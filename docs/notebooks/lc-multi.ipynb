{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run notebook_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_period = 4.887803076\n",
    "lit_t0 = 124.8130808"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lightkurve as lk\n",
    "from collections import OrderedDict\n",
    "\n",
    "kepler_lcfs = lk.search_lightcurvefile(\"HAT-P-11\", mission=\"Kepler\").download_all()\n",
    "kepler_lc = kepler_lcfs.PDCSAP_FLUX.stitch().remove_nans()\n",
    "kepler_t = np.ascontiguousarray(kepler_lc.time, dtype=np.float64)\n",
    "kepler_y = np.ascontiguousarray(1e3 * (kepler_lc.flux - 1), dtype=np.float64)\n",
    "kepler_yerr = np.ascontiguousarray(1e3 * kepler_lc.flux_err, dtype=np.float64)\n",
    "\n",
    "hdr = kepler_lcfs[0].hdu[1].header\n",
    "kepler_texp = hdr[\"FRAMETIM\"] * hdr[\"NUM_FRM\"]\n",
    "kepler_texp /= 60.0 * 60.0 * 24.0\n",
    "\n",
    "tess_lcfs = lk.search_lightcurvefile(\"HAT-P-11\", mission=\"TESS\").download_all()\n",
    "tess_lc = tess_lcfs.PDCSAP_FLUX.stitch().remove_nans()\n",
    "tess_t = np.ascontiguousarray(tess_lc.time + 2457000 - 2454833, dtype=np.float64)\n",
    "tess_y = np.ascontiguousarray(1e3 * (tess_lc.flux - 1), dtype=np.float64)\n",
    "tess_yerr = np.ascontiguousarray(1e3 * tess_lc.flux_err, dtype=np.float64)\n",
    "\n",
    "hdr = tess_lcfs[0].hdu[1].header\n",
    "tess_texp = hdr[\"FRAMETIM\"] * hdr[\"NUM_FRM\"]\n",
    "tess_texp /= 60.0 * 60.0 * 24.0\n",
    "\n",
    "datasets = OrderedDict(\n",
    "    [\n",
    "        (\"Kepler\", [kepler_t, kepler_y, kepler_yerr, kepler_texp]),\n",
    "        (\"TESS\", [tess_t, tess_y, tess_yerr, tess_texp]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "for name, (t, y, _, _) in datasets.items():\n",
    "    plt.plot(t, y, label=name)\n",
    "plt.legend(fontsize=10)\n",
    "plt.xlabel(\"time [KBJD]\")\n",
    "_ = plt.ylabel(\"relative flux [ppt]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import exoplanet as xo\n",
    "import theano.tensor as tt\n",
    "from functools import partial\n",
    "\n",
    "x_min = min(np.min(x) for x, _, _, _ in datasets.values())\n",
    "x_max = max(np.max(x) for x, _, _, _ in datasets.values())\n",
    "x_mid = 0.5 * (x_min + x_max)\n",
    "t0_ref = lit_t0 + lit_period * np.round((x_mid - lit_t0) / lit_period)\n",
    "\n",
    "for i in range(10):\n",
    "    with pm.Model() as model:\n",
    "\n",
    "        # Shared orbital parameters\n",
    "        period = pm.Lognormal(\"period\", mu=np.log(lit_period), sigma=1.0)\n",
    "        t0 = pm.Normal(\"t0\", mu=t0_ref, sigma=1.0)\n",
    "        dur = pm.Lognormal(\"dur\", mu=np.log(0.1), sigma=10.0)\n",
    "        b = xo.UnitUniform(\"b\")\n",
    "        ld_arg = 1 - tt.sqrt(1 - b ** 2)\n",
    "        orbit = xo.orbits.KeplerianOrbit(period=period, duration=dur, t0=t0, b=b)\n",
    "\n",
    "        # We'll also say that the timescale of the GP will be shared\n",
    "        ell = pm.InverseGamma(\n",
    "            \"ell\", testval=2.0, **xo.estimate_inverse_gamma_parameters(1.0, 5.0)\n",
    "        )\n",
    "\n",
    "        # Loop over the instruments\n",
    "        parameters = dict()\n",
    "        lc_models = dict()\n",
    "        gp_preds = dict()\n",
    "        gp_preds_with_mean = dict()\n",
    "        for n, (name, (x, y, yerr, texp)) in enumerate(datasets.items()):\n",
    "\n",
    "            # We define the per-instrument parameters in a submodel so that we\n",
    "            # don't have to prefix the names manually\n",
    "            with pm.Model(name=name, model=model):\n",
    "                # The flux zero point\n",
    "                mean = pm.Normal(\"mean\", mu=0.0, sigma=10.0)\n",
    "\n",
    "                # The limb darkening\n",
    "                u = xo.distributions.QuadLimbDark(\"u\")\n",
    "                star = xo.LimbDarkLightCurve(u)\n",
    "\n",
    "                # The radius ratio\n",
    "                approx_depth = pm.Lognormal(\"approx_depth\", mu=np.log(4e-3), sigma=10)\n",
    "                ld = 1 - u[0] * ld_arg - u[1] * ld_arg ** 2\n",
    "                ror = pm.Deterministic(\"ror\", tt.sqrt(approx_depth / ld))\n",
    "\n",
    "                # Noise parameters\n",
    "                med_yerr = np.median(yerr)\n",
    "                std = np.std(y)\n",
    "                sigma = pm.InverseGamma(\n",
    "                    \"sigma\",\n",
    "                    testval=med_yerr,\n",
    "                    **xo.estimate_inverse_gamma_parameters(med_yerr, 0.5 * std),\n",
    "                )\n",
    "                S_tot = pm.InverseGamma(\n",
    "                    \"S_tot\",\n",
    "                    testval=med_yerr,\n",
    "                    **xo.estimate_inverse_gamma_parameters(\n",
    "                        med_yerr ** 2, 0.25 * std ** 2\n",
    "                    ),\n",
    "                )\n",
    "\n",
    "                # Keep track of the parameters for optimization\n",
    "                parameters[name] = [mean, u, approx_depth]\n",
    "                parameters[f\"{name}_noise\"] = [sigma, S_tot]\n",
    "\n",
    "            # The light curve model\n",
    "            def lc_model(mean, star, ror, texp, t):\n",
    "                return mean + 1e3 * tt.sum(\n",
    "                    star.get_light_curve(orbit=orbit, r=ror, t=t, texp=texp), axis=-1\n",
    "                )\n",
    "\n",
    "            lc_model = partial(lc_model, mean, star, ror, texp)\n",
    "            lc_models[name] = lc_model\n",
    "\n",
    "            # The Gaussian Process noise model\n",
    "            kernel = xo.gp.terms.SHOTerm(S_tot=S_tot, w0=2 * np.pi / ell, Q=1.0 / 3)\n",
    "            gp = xo.gp.GP(kernel, x, yerr ** 2 + sigma ** 2, mean=lc_model)\n",
    "            gp.marginal(f\"{name}_obs\", observed=y)\n",
    "            gp_preds[name] = gp.predict()\n",
    "            gp_preds_with_mean[name] = gp.predict(predict_mean=True)\n",
    "\n",
    "        # Optimize the model\n",
    "        map_soln = model.test_point\n",
    "        for name in datasets:\n",
    "            map_soln = xo.optimize(map_soln, parameters[name])\n",
    "        for name in datasets:\n",
    "            map_soln = xo.optimize(map_soln, parameters[name] + [dur, b])\n",
    "            map_soln = xo.optimize(map_soln, parameters[f\"{name}_noise\"])\n",
    "        map_soln = xo.optimize(map_soln)\n",
    "\n",
    "        # Do some sigma clipping\n",
    "        num = dict((name, len(datasets[name][0])) for name in datasets)\n",
    "        clipped = dict()\n",
    "        masks = dict()\n",
    "        for name in datasets:\n",
    "            mdl = xo.eval_in_model(gp_preds_with_mean[name], map_soln)\n",
    "            resid = datasets[name][1] - mdl\n",
    "            sigma = np.sqrt(np.median((resid - np.median(resid)) ** 2))\n",
    "            masks[name] = np.abs(resid - np.median(resid)) < 7 * sigma\n",
    "            clipped[name] = num[name] - masks[name].sum()\n",
    "            print(f\"Sigma clipped {clipped[name]} {name} light curve points\")\n",
    "        if all(c < 10 for c in clipped.values()):\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            for name in datasets:\n",
    "                datasets[name][0] = datasets[name][0][masks[name]]\n",
    "                datasets[name][1] = datasets[name][1][masks[name]]\n",
    "                datasets[name][2] = datasets[name][2][masks[name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_soln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = np.linspace(-0.2, 0.2, 500)\n",
    "\n",
    "with model:\n",
    "    trends = xo.eval_in_model([gp_preds[k] for k in datasets], map_soln)\n",
    "    phase_curves = xo.eval_in_model([lc_models[k](t0 + dt) for k in datasets], map_soln)\n",
    "\n",
    "fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(8, 6))\n",
    "\n",
    "for n, name in enumerate(datasets):\n",
    "    ax = axes[n]\n",
    "\n",
    "    x, y = datasets[name][:2]\n",
    "\n",
    "    period = map_soln[\"period\"]\n",
    "    folded = (x - map_soln[\"t0\"] + 0.5 * period) % period - 0.5 * period\n",
    "    m = np.abs(folded) < 0.2\n",
    "    ax.plot(\n",
    "        folded[m],\n",
    "        (y - trends[n] - map_soln[f\"{name}_mean\"])[m],\n",
    "        \".k\",\n",
    "        alpha=0.3,\n",
    "        mec=\"none\",\n",
    "    )\n",
    "    ax.plot(dt, phase_curves[n] - map_soln[f\"{name}_mean\"], f\"C{n}\", label=name)\n",
    "    ax.annotate(\n",
    "        name,\n",
    "        xy=(1, 0),\n",
    "        xycoords=\"axes fraction\",\n",
    "        va=\"bottom\",\n",
    "        ha=\"right\",\n",
    "        xytext=(-3, 3),\n",
    "        textcoords=\"offset points\",\n",
    "        fontsize=14,\n",
    "    )\n",
    "\n",
    "axes[-1].set_xlim(-0.15, 0.15)\n",
    "axes[-1].set_xlabel(\"time since transit [days]\")\n",
    "for ax in axes:\n",
    "    ax.set_ylabel(\"relative flux [ppt]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(11)\n",
    "with model:\n",
    "    trace = xo.sample(\n",
    "        tune=3500, draws=3000, start=map_soln, chains=4, initial_accept=0.5,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(trace[\"Kepler_ror\"], 30, density=True, histtype=\"step\")\n",
    "plt.hist(trace[\"TESS_ror\"], 30, density=True, histtype=\"step\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "\n",
    "fig = corner.corner(trace[\"Kepler_u\"], color=\"C0\")\n",
    "corner.corner(trace[\"TESS_u\"], color=\"C1\", fig=fig, labels=[\"$u_1$\", \"$u_2$\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
